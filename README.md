## RAG Developers' Stack

RAG stands for Retrieval Augmented Generation.

RAG helps to enhance the accuracy of LLM answers by providing relevant context from external knowledge bases.

RAG Developers Stack

LLMs - LLMs are advanced deep learning models based on transformers decoders. We have both open-source and closed LLMs.

Frameworks - Frameworks help to develop RAG applications without coding everything from scratch. LangChain and Llama Index are some of the popular frameworks for building RAG applications. 

Vector Databases - Vector databases store the text chunks, metadata and their embeddings. 

Data Extraction - RAG applications require extraction of data from websites and documents (PDF, word, slides, etc.) 

Open LLMs Access - Ollama is a tool that helps to use open LLMs locally. Platforms like Groq, Hugging Face and Together AI offer API access to open LLMs.

Text Embeddings - Text embeddings are used to transform text chunks into embeddings for similar chunks retrieval. Apart from text embedding models, image embedding and multi-modal embedding models are also available.

Evaluation - Giskard and Ragas are the popular libraries to evaluate RAG applications. 

![rag-stack](https://github.com/user-attachments/assets/7450e0e0-48d0-42c6-880d-94c0b1ac4262)
